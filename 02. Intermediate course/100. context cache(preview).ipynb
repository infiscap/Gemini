{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "context cache 만들"
      ],
      "metadata": {
        "id": "DNf4vYMQhwqh"
      },
      "id": "DNf4vYMQhwqh"
    },
    {
      "cell_type": "code",
      "id": "mxuzhyuzjLpXUxVKjsQ9oHb6",
      "metadata": {
        "tags": [],
        "id": "mxuzhyuzjLpXUxVKjsQ9oHb6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737090471700,
          "user_tz": -540,
          "elapsed": 1002,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "source": [
        "PROJECT_ID=!gcloud config get-value project\n",
        "PROJECT_ID=PROJECT_ID[0]\n",
        "LOCATION=\"us-east1\"\n",
        "MODEL_ID=\"gemini-1.5-pro-002\"\n",
        "DISPLAY_NAME=\"example-cache\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "import datetime\n",
        "\n",
        "from vertexai.generative_models import Part\n",
        "from vertexai.preview import caching\n",
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "djfgB4YVot8C",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737090569792,
          "user_tz": -540,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "djfgB4YVot8C",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction = \"\"\"\n",
        "너는 전문 연구가이다.\n",
        "너는 주워진 자원에서 항상 진실만을 말하며 새로운 사실을 만들지는 않는다.\n",
        "제공된 논문을 기반으로 질문에 답변하자.\n",
        "\"\"\"\n",
        "\n",
        "contents = [\n",
        "    Part.from_uri(\n",
        "        \"gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf\",\n",
        "        mime_type=\"application/pdf\",\n",
        "    ),\n",
        "    Part.from_uri(\n",
        "        \"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n",
        "        mime_type=\"application/pdf\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "cached_content = caching.CachedContent.create(\n",
        "    model_name=MODEL_ID,\n",
        "    system_instruction=system_instruction,\n",
        "    contents=contents,\n",
        "    ttl=datetime.timedelta(minutes=60),\n",
        "    display_name=DISPLAY_NAME,\n",
        ")\n",
        "\n",
        "print(cached_content.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhnxmGKEh1ei",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737090496400,
          "user_tz": -540,
          "elapsed": 24204,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5af58769-7421-4319-d652-58fc09c59c28"
      },
      "id": "zhnxmGKEh1ei",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1295242289706172416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "context cache 사"
      ],
      "metadata": {
        "id": "3usGRZrXj5Oc"
      },
      "id": "3usGRZrXj5Oc"
    },
    {
      "cell_type": "code",
      "source": [
        "cached_content = caching.CachedContent(cached_content_name=cached_content.name)\n",
        "\n",
        "model = GenerativeModel.from_cached_content(cached_content=cached_content)\n",
        "\n",
        "response = model.generate_content(\"논문의 내용은 무엇인가?\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZBXswwKi1tW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737090815861,
          "user_tz": -540,
          "elapsed": 23660,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0048d72c-d798-4b88-a600-a877c9d6ddb6"
      },
      "id": "SZBXswwKi1tW",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 보고서는 이미지, 오디오, 비디오 및 텍스트 이해를 포괄하는 뛰어난 기능을 가진 새로운 멀티모달 모델 제품군인 제미나이를 소개합니다. 제미나이 제품군은 복잡한 추론 작업에서 장치 메모리 제약 사용 사례에 이르기까지 애플리케이션에 적합한 울트라, 프로 및 나노 크기로 구성됩니다. 광범위한 벤치마크에 대한 평가 결과, 가장 기능이 뛰어난 제미나이 울트라 모델이 이러한 벤치마크 32개 중 30개에서 최첨단 기술을 발전시켰으며 특히 잘 연구된 시험 벤치마크 MMLU에서 인간 전문가 수준의 성능을 달성한 최초의 모델이자 조사한 20개의 멀티모달 벤치마크 각각에서 최첨단 기술을 개선한 모델임이 입증되었습니다. 교차 모달 추론 및 언어 이해에 대한 제미나이 제품군의 새로운 기능이 광범위한 사용 사례를 가능하게 할 것이라고 생각합니다. 제미나이, 제미나이 어드밴스드, 구글 AI 스튜디오 및 클라우드 버텍스 AI를 포함한 서비스를 통해 사용자에게 제미나이 모델을 책임감 있게 사후 교육하고 배포하는 접근 방식에 대해 논의합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What are the papers about?\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV8v4kT6rIDU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737090876973,
          "user_tz": -540,
          "elapsed": 22185,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "dbd69d60-e943-416a-ca1e-82b2d9ac42f1"
      },
      "id": "tV8v4kT6rIDU",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 논문은 이미지, 오디오, 비디오 및 텍스트 이해를 통해 놀라운 기능을 보이는 새로운 다중 모달 모델 제품군인 Gemini를 소개합니다. Gemini 제품군은 복잡한 추론 작업에서 장치 메모리 제약이 있는 사용 사례에 이르기까지 다양한 응용 프로그램에 적합한 Ultra, Pro 및 Nano 크기로 구성됩니다. 다양한 벤치마크에 대한 평가 결과, 가장 성능이 뛰어난 Gemini Ultra 모델은 32개 벤치마크 중 30개에서 최첨단 기술을 발전시켰으며, 특히 잘 연구된 시험 벤치마크 MMLU에서 인간 전문가 수준의 성능을 달성한 최초의 모델이었으며, 검토한 20개의 다중 모달 벤치마크 각각에서 최첨단 기술을 개선했습니다. 교차 모달 추론 및 언어 이해에 대한 Gemini 제품군의 새로운 기능은 다양한 사용 사례를 가능하게 할 것으로 예상됩니다. 이 보고서는 포스트 교육 접근 방식에 대해 논의하고 Gemini, Gemini Advanced, Google AI Studio 및 Cloud Vertex AI를 포함한 서비스를 통해 사용자에게 Gemini 모델을 책임감 있게 배포하는 방법에 대해 논의합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "context cache 정보 가져오기"
      ],
      "metadata": {
        "id": "y7YRbIqYkBCw"
      },
      "id": "y7YRbIqYkBCw"
    },
    {
      "cell_type": "code",
      "source": [
        "cache_list = caching.CachedContent.list()\n",
        "\n",
        "for cached_content in cache_list:\n",
        "    print(f\"Cache '{cached_content.name}' for model '{cached_content.model_name}'\")\n",
        "    print(f\"Last updated at: {cached_content.update_time}\")\n",
        "    print(f\"Expires at: {cached_content.expire_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1n5oucujS5d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737091070340,
          "user_tz": -540,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "35dd59f1-c34f-461d-aac3-5207f35b7ceb"
      },
      "id": "V1n5oucujS5d",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache '1295242289706172416' for model 'projects/younkicho-364103/locations/us-east1/publishers/google/models/gemini-1.5-pro-002'\n",
            "Last updated at: 2025-01-17 05:07:55.869092+00:00\n",
            "Expires at: 2025-01-17 06:07:55.845806+00:00\n",
            "Cache '250407176156217344' for model 'projects/younkicho-364103/locations/us-east1/publishers/google/models/gemini-1.5-pro-002'\n",
            "Last updated at: 2025-01-17 05:05:42.112630+00:00\n",
            "Expires at: 2025-01-17 06:05:42.101691+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "context cache update"
      ],
      "metadata": {
        "id": "5qYsEBl8kS6o"
      },
      "id": "5qYsEBl8kS6o"
    },
    {
      "cell_type": "code",
      "source": [
        "cached_content.update(ttl=datetime.timedelta(hours=1))\n",
        "cached_content.refresh()\n",
        "\n",
        "print(cached_content.expire_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8AHz0bskAh1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737091142215,
          "user_tz": -540,
          "elapsed": 1410,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3d557dce-12dc-40cc-cdfb-9427c3229ddf"
      },
      "id": "h8AHz0bskAh1",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-17 06:19:04.775970+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "context cache delete"
      ],
      "metadata": {
        "id": "SgsfD1dPlKDV"
      },
      "id": "SgsfD1dPlKDV"
    },
    {
      "cell_type": "code",
      "source": [
        "cached_content.delete()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA8d_0j4k6l1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1737091155395,
          "user_tz": -540,
          "elapsed": 488,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a25270cd-e23a-45a1-a012-cc5c90f56e47"
      },
      "id": "nA8d_0j4k6l1",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.base:Deleting CachedContent : projects/429718924597/locations/us-east1/cachedContents/250407176156217344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4oKLlB9lUHA"
      },
      "id": "J4oKLlB9lUHA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "younki.cho (Jan 17, 2025, 1:26:25 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}